\chapter{Verification in LiquidHaskell}
\label{ch:verification}
This chapter details the formal verification of the leftist heap implementation using \texttt{LiquidHaskell}. We demonstrate how refinement types can be used to enforce complex structural and behavioral invariants, ensuring the correctness of our priority queue implementation.

\section{Refined Data Structure}
The cornerstone of the verification is the refined data type for the leftist heap itself.
We encode the core invariants of the data structure directly into its type definition.

\begin{code}
  data LeftistHeap a = EmptyHeap
        | HeapNode { value :: a
           , left  :: LeftistHeapBound a value
           , right :: {v : LeftistHeapBound a value  | rrank v <= rrank left }
           , rank :: {r : Nat | r == 1 + rrank right}
          }
\end{code}

This refined definition enforces three key invariants:
\begin{enumerate}
    \item \textbf{Heap Property:} The value at any node is the minimum in its subtree.
    This is captured by the \texttt{LeftistHeapBound a X} refinement type on the \texttt{left} and \texttt{right} children.
    \texttt{isLowerBound} is a recursively defined predicate that checks if a given value is less than or equal to all elements in a heap.
    \begin{code}
  {-@ type LeftistHeapBound a X = { h : LeftistHeap a | isLowerBound X h} @-}
  {-@ reflect isLowerBound @-} 
  isLowerBound :: (Ord a) => a -> LeftistHeap a -> Bool
  isLowerBound _ EmptyHeap = True
  isLowerBound v (HeapNode x l r _) = 
      v <= x && isLowerBound v l && isLowerBound v r
    \end{code}
    
    \item \textbf{Leftist Property:} For any node, the rank of its right child is less than or equal to the rank of its left child. This is expressed by \texttt{rrank v <= rrank left}. This property is what ensures that the right spine of the heap is short, leading to logarithmic time complexity for merge operations.
    
    \item \textbf{Rank Property:} The rank of a node is defined as one plus the rank of its right child. This is specified by \texttt{rank :: \{r : Nat | r == 1 + rrank right\}}. The rank of an \texttt{EmptyHeap} is 0.
\end{enumerate}

By embedding these invariants directly into the type, \texttt{LiquidHaskell}'s verifier will ensure that any function constructing or modifying a \texttt{LeftistHeap} respects them.

\section{Refined Heap Operations}
Following the interface defined in Chapter~\ref{lst:pq}, we refine the types of the heap operations to ensure they maintain the invariants of the leftist heap.
Unfortunately, due to limitations in \texttt{LiquidHaskell}'s current support for type classes,
we cannot directly define the invariants for the \texttt{PriorityQueue} type class.
Instead, we provide refined type signatures for each operation individually.
To express these invariants and reason about the behavior of our functions, we use several features of \texttt{LiquidHaskell}.

\textbf{Measures} (see Section~\ref{sec:reflection}) are functions from Haskell's term-level to the refinement logic's domain. We define several measures:
\begin{itemize}
	\item \texttt{size}: Computes the total number of nodes in the heap, useful for termination metrics (see Section~\ref{sec:termination}).
	\item \texttt{rrank}: Returns the rank of a heap, which is crucial for the leftist property.
	\item \texttt{bag}: Converts the heap into a multiset (or bag) of its elements. This is invaluable for proving that operations like \texttt{heapMerge} do not lose or duplicate elements.
\end{itemize}

\textbf{Reflected Functions} (see Section~\ref{sec:reflection}) allow us to use standard Haskell functions within the refinement logic. We use this for \texttt{isLowerBound}, \texttt{heapMerge}, and \texttt{makeHeapNode}.
This allows us to reason about their behavior during verification.


In the following sections,
we present the refined type signatures and implementations of the key heap operations,
along with explanations of how they maintain the invariants of the leftist heap.
\subsection{Heap isEmpty}
This function checks if the heap is empty.
There is no invariate to maintain here, but we define a measure to help with other proofs.
\begin{code}
  {-@ measure heapIsEmpty @-}
  {-@ heapIsEmpty :: LeftistHeap a -> Bool @-}
  heapIsEmpty :: (Ord a) => LeftistHeap a -> Bool
  heapIsEmpty EmptyHeap = True
  heapIsEmpty _ = False
\end{code}
\subsection{Heap findMin}
To retrieve the minimum element from a non-empty heap, we define \texttt{heapFindMin}.
We restrict its input to non-empty heaps and specify that the returned value is a lower bound for the heap.
As per the heap property, the minimum element is always at the root of the heap.
This can directly be extracted from the \texttt{HeapNode} and \texttt{LiquidHaskell} can verify that this value is indeed a lower bound for the entire heap.
\begin{code}
  {-@ heapFindMin :: h : {h : LeftistHeap a | not (heapIsEmpty h)} 
        -> {v : a | isLowerBound v h} @-}
  heapFindMin :: (Ord a) => LeftistHeap a -> a
  heapFindMin (HeapNode x _ _ _) = x
\end{code}

\subsection{Heap Merge}
The most critical operation for a leftist heap is \texttt{heapMerge}. 
Its correctness is fundamental to the correctness of \texttt{insert} and \texttt{deleteMin}.
The type signature for \texttt{heapMerge} specifies its behavior:
\begin{code}
  heapMerge :: h1 : LeftistHeap a 
        -> h2: LeftistHeap a 
        -> {h : LeftistHeap a | (HeapMergeMin h1 h2 h) 
                             && (BagUnion h1 h2 h)}
        / [size h1, size h2, 0]
\end{code}
This signature guarantees that merging two valid leftist heaps results in a new valid leftist heap,
that the heap property is maintained, and that the set of elements is preserved.

To express these properties, we have defined two predicates:
\begin{code}
 predicate HeapMergeMin H1 H2 H = 
    ((not (heapIsEmpty H1) && not (heapIsEmpty H2)) => 
    isLowerBound (min (heapFindMin H1) (heapFindMin H2)) H )
 predicate BagUnion H1 H2 H = 
    (bag H == B.union (bag H1) (bag H2))
\end{code}

\texttt{HeapMergeMin} asserts that the resulting heap \texttt{H} respects the heap property relative to the minimum elements of the input heaps \texttt{H1} and \texttt{H2}.
\texttt{BagUnion} asserts that the elements in the merged heap are the union of the elements from the input heaps.

The implementation of \texttt{heapMerge} involves a recursive call.
To help the SMT solver prove that the invariants hold through this recursion,
we provide helper lemmas. For example, in the case where \texttt{x1 <= x2},
we merge the right child of the first heap (\texttt{r1}) with the second heap (\texttt{h2}).
We must provide the proof for \texttt{LiquidHaskell} that the root value \texttt{x1} is a lower bound for this newly merged heap.

\begin{code}
heapMerge h1@(HeapNode x1 l1 r1 _) h2@(HeapNode x2 l2 r2 _)
  | x1 <= x2 = makeHeapNode x1 l1 ((heapMerge r1 h2) 
    `withProof` lemma_merge_case1 x1 x2 r1 h2)
  | otherwise = makeHeapNode x2 l2 ((heapMerge h1 r2)
    `withProof` lemma_heapMerge_case2 x2 x1 r2 h1)
\end{code}

The \texttt{makeHeapNode} requires that its first argument is a lower bound for both its left and right children.
\begin{code}
  makeHeapNode :: x : a
   -> {h : LeftistHeap a | isLowerBound x h}
   -> {h : LeftistHeap a | isLowerBound x h}
   -> {h : LeftistHeap a | isLowerBound x h}

\end{code}
In this context, \texttt{LiquidHaskell} can automatically infer that the root value (\texttt{x1} or \texttt{x2}) is a lower bound for the left child, since it is inherited from the parent heap.
However, for the right child, which is obtained from a recursive call to \texttt{heapMerge}, the proof must be supplied explicitly.
This proof obligation is discharged by auxiliary lemmas such as \texttt{lemma\_merge\_case1} and \texttt{lemma\_merge\_case2}.

The first lemma, \texttt{lemma\_merge\_case1}, handles the case where \texttt{x1 <= x2}.
It states that if \texttt{x1} is a lower bound for \texttt{r1} and \texttt{x2} is a lower bound for \texttt{h2}, then \texttt{x1} is also a lower bound for the result of merging \texttt{r1} and \texttt{h2}.
\begin{code}
  lemma_merge_case1 :: x1 : a
    -> x2 : {a |  x1  <= x2}
    -> r1 : LeftistHeapBound a x1
    -> h2 : {LeftistHeapBound a x2 | not (heapIsEmpty h2)}
    -> {isLowerBound x1 (heapMerge r1 h2)}
    / [size r1, size h2, 1]
\end{code}

The proof proceeds by case analysis on the structure of \texttt{r1}.

\begin{code}
  lemma_merge_case1 x1 x2 EmptyHeap h2 =
    isLowerBound x1 (heapMerge EmptyHeap h2)
      ? lemma_isLowerBound_transitive x1 x2 h2
      *** QED
  lemma_merge_case1 x1 x2 r1@(HeapNode _ _ _ _) h2@(HeapNode _ _ _ _) =
    isLowerBound x1 (heapMerged)
      ? (lemma_isLowerBound_transitive x1 (min (heapFindMin r1) (heapFindMin h2)) (heapMerged))
      *** QED
   where
    heapMerged = heapMerge r1 h2
\end{code}

In the base case, when \texttt{r1} is empty, the merge simply returns \texttt{h2}.
Since \texttt{x1 <= x2} and \texttt{x2} is a lower bound for \texttt{h2}, it follows by transitivity that \texttt{x1} is also a lower bound for \texttt{h2}.
In the inductive case, both heaps are non-empty.
The result of \texttt{heapMerge r1 h2} again satisfies the lower-bound property, which is established through the transitive lemma below.


\subsubsection*{Transitivity of Lower Bounds}
The lemma \texttt{lemma\_isLowerBound\_transitive} expresses the fundamental transitivity of the lower-bound relation across heaps.
It is used repeatedly throughout the verification of heap merge.
\begin{code}
{-@ lemma_isLowerBound_transitive :: x : a
      -> y : {v : a | x <= v}
      -> h : {h : LeftistHeap a | isLowerBound y h}
      -> {isLowerBound x h}
@-}
lemma_isLowerBound_transitive :: (Ord a) => a -> a -> LeftistHeap a -> Proof
lemma_isLowerBound_transitive x y EmptyHeap = ()
lemma_isLowerBound_transitive x y (HeapNode z l r _) = lemma_isLowerBound_transitive x y l &&& lemma_isLowerBound_transitive x y r *** QED
\end{code}

This lemma formalizes the intuitive notion that if \texttt{x <= y} and \texttt{y} is a lower bound for all elements of a heap \texttt{h}, then \texttt{x} must also be a lower bound for \texttt{h}.
It is a small but essential proof component that supports most of the recursive heap reasoning.

\subsubsection*{Symmetric Case}
A symmetric argument applies to the case where \texttt{x1 > x2}.
The second lemma, \texttt{lemma\_merge\_case2}, follows the same structure as \texttt{lemma\_merge\_case1} but exchanges the roles of the input heaps and their bounds.

\begin{code}
  lemma_heapMerge_case2 :: x2 : a
    -> x1 : { v : a |  x2  <= v}
    -> r1 : {h : LeftistHeap a | isLowerBound x2 h}
    -> h2 : {h : LeftistHeap a | not (heapIsEmpty h) && isLowerBound x1 h}
    -> {isLowerBound x2 (heapMerge h2 r1)} 
    / [size h2, size r1, 1]
\end{code}
The reason we cannot simply reuse \texttt{lemma\_merge\_case1} is that the order of the arguments to \texttt{heapMerge} is swapped in this case.
And also the termination metric must reflect which arguments are reduced in the recursive call.
We discuss this in the next section.

\subsubsection*{Dealing with Termination and Recursion}

\texttt{LiquidHaskell} must ensure that all recursive functions terminate. 
For \texttt{heapMerge}, we provide the following termination metric:

\begin{code}
/ [size h1, size h2, 0]
\end{code}

This specifies a lexicographically ordered tuple. 
\texttt{LiquidHaskell} verifies that for every recursive call within \texttt{heapMerge}, either the size of the first argument or the size of the second argument decreases. 
In our case, one of the heaps is replaced by its right child, which is strictly smaller, thereby decreasing the total size and ensuring termination. 
The trailing \texttt{0} acts as a tie-breaker: it allows us to extend the tuple later when reasoning about mutually recursive functions.

The lemma \texttt{lemma\_merge\_case1} is mutually recursive with \texttt{heapMerge}, which requires us to make explicit which arguments of \texttt{heapMerge} are reduced in the body of the function (for instance, \texttt{r1} compared to \texttt{h1}). 
To capture this, we use the following termination metric for \texttt{lemma\_merge\_case1}:

\begin{code}
/ [size r1, size h2, 1]
\end{code}

Here the final \texttt{1} ensures that 
\[
[size\ r1, size\ h2, 0] \;<\; [size\ r1, size\ h2, 1]
\]
in lexicographic order. 
This indicates that when \texttt{lemma\_merge\_case1} calls \texttt{heapMerge}, it is making progress towards termination.
In the same way, other supporting lemmas are also assigned termination metrics, which are automatically checked by the verifier.


Together, these lemmas ensure that \texttt{heapMerge} preserves the heap property and terminates correctly for all valid inputs.
They form the core of the mechanized proof that merging two leftist heaps yields a well-formed, correctly ordered, and element-preserving result.
\subsection{Heap Insert}
Heap insertion is implemented using heap merging.
The refined type signature for \texttt{heapInsert} specifies that
inserting an element into a non-empty heap produces a new heap where
the inserted element is a lower bound for the resulting heap if it is smaller than the minimum of the original heap
and that the multiset of elements is updated accordingly.

\begin{code}
heapInsert :: x : a
  -> h1 : LeftistHeap a
  -> {h : LeftistHeap a |
        not (heapIsEmpty h1) 
          => isLowerBound (min x (heapFindMin h1)) h
        && bag h = B.put x (bag h1) }
\end{code}
LiquidHaskell can automatically verify that the properties hold, given the correctness of \texttt{heapMerge}.
So no additional lemmas are required here.


\subsection{Heap SplitMin}

The \texttt{SplitMin} operation decomposes a heap into its minimum element and the remaining heap. 
If the heap is empty, the result is an empty view. 
This operation can be expressed elegantly in LiquidHaskell using a single refinement predicate that encodes both cases,
the empty and non-empty heap, guarded by logical conditions.

\begin{code}
{-@ predicate SplitOK H S =
  (heapIsEmpty H => isEmptyView S)
    && (not (heapIsEmpty H) => not (isEmptyView S)
      && getMinValue S == heapFindMin H
      && bag H == B.put (getMinValue S) (bag (getRestHeap S)))
@-}

{-@ heapSplit :: (Ord a)
              => h:LeftistHeap a
              -> { s:MinView LeftistHeap a | SplitOK h s } @-}
heapSplit :: (Ord a) => LeftistHeap a -> MinView LeftistHeap a
heapSplit EmptyHeap          = EmptyView
heapSplit (HeapNode x l r _) = Min x (heapMerge l r)
\end{code}

The refinement predicate \texttt{SplitOK} expresses the relationship between the input heap \texttt{H} 
and the result \texttt{S} of the \texttt{heapSplit} operation in a case-distinguishing manner:

\begin{itemize}
  \item \textbf{Empty heap case.}  
  When \texttt{heapIsEmpty H} holds, the resulting view \texttt{S} must be empty, i.e., \texttt{isEmptyView S} is true.  
  This ensures that the field selectors \texttt{getMinValue} and \texttt{getRestHeap} are never applied to an empty structure, 
  maintaining totality of the specification.

  \item \textbf{Non-empty heap case.}  
  When \texttt{H} is non-empty, the result must be of the form \texttt{Min} with fields \texttt{minValue} and \texttt{restHeap}.  
  In this branch, the following properties must hold:
  \begin{enumerate}
    \item The minimum value of the view matches the minimum of the input heap:
      \[
        \texttt{getMinValue S = heapFindMin H}.
      \]
    \item The multiset of elements is preserved:
      \[
        \texttt{bag H = B.put (getMinValue S) (bag (getRestHeap S))}.
      \]
  \end{enumerate}
\end{itemize}

The implementation follows the specification precisely. 
For an empty heap, \texttt{heapSplit} simply returns \texttt{EmptyView}. 
For a non-empty heap of the form \texttt{HeapNode x l r \_}, the result is \texttt{Min x (heapMerge l r)}.
The correctness of this implementation relies on two key facts:

\begin{enumerate}
  \item The root element \texttt{x} of a non-empty leftist heap is its minimum, 
        establishing the equality \texttt{getMinValue S == heapFindMin H}.
  \item The \texttt{heapMerge} operation preserves the multiset of elements, 
        ensuring the bag equality in the refinement holds.
\end{enumerate}

Thus, the \texttt{heapSplit} function correctly decomposes any leftist heap into its minimal element and the remainder,
while preserving both structural and content invariants as captured by \texttt{SplitOK}.
\section{Challenges and Workarounds}
The primary challenge in verifying the leftist heap was proving that the structural invariants are preserved by the recursive \texttt{heapMerge} function. The SMT solver, while powerful, cannot always deduce these properties on its own, especially when they rely on inductive reasoning over a recursive data structure.

The main "workaround" was to guide the solver by providing explicit proofs in the form of lemmas (\texttt{lemma\_merge\_case1} and \texttt{lemma\_heapMerge\_case2}). These lemmas essentially break down the proof of correctness into smaller, more manageable steps that the solver can verify. They act as explicit induction steps. For example, \texttt{lemma\_merge\_case1} proves a key property about the recursive call, which \texttt{LiquidHaskell} can then use to prove the property for the function as a whole. This pattern of using helper lemmas to discharge proof obligations is common in formal verification with refinement types.

